import torch
import torch.nn as nn
import torch.optim as optim
from torch.nn.utils.rnn import pad_sequence

import sys
sys.path.append(r'f:\GraduateStudent')
from Projects.Model.NN import Transformer
from Projects.Utils.tools import *

device = utils_getDevice()

# def test_transformer_complete():
#     """å®Œæ•´æµ‹è¯•Transformeræ¨¡å‹"""
#     print("=== å¼€å§‹æµ‹è¯•å®Œæ•´Transformeræ¨¡å‹ ===")
    
#     # å°è§„æ¨¡å‚æ•°è®¾ç½®ï¼ˆä¾¿äºå¿«é€Ÿæµ‹è¯•ï¼‰
#     src_vocab_size = 100
#     tgt_vocab_size = 80
#     d_model = 32
#     num_layers = 2
#     num_heads = 4
#     d_ff = 64
#     batch_size = 4
#     src_seq_len = 10
#     tgt_seq_len = 8
#     padding_idx = 0
    
#     # åˆ›å»ºæ¨¡å‹
#     transformer = Transformer(
#         src_vocab_size=src_vocab_size,
#         tgt_vocab_size=tgt_vocab_size,
#         d_model=d_model,
#         num_layers=num_layers,
#         num_heads=num_heads,
#         d_ff=d_ff,
#         max_seq_length=32,
#         dropout=0.1,
#         padding_idx=padding_idx
#     ).to(device)
    
#     print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
#     # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥æ•°æ®
#     src = torch.randint(0, src_vocab_size, (batch_size, src_seq_len)).to(device)
#     tgt = torch.randint(0, tgt_vocab_size, (batch_size, tgt_seq_len)).to(device)
    
#     print(f"æºåºåˆ—å½¢çŠ¶: {src.shape}")
#     print(f"ç›®æ ‡åºåˆ—å½¢çŠ¶: {tgt.shape}")
    
#     # åˆ›å»ºå„ç§æ©ç 
#     src_mask = UTools_createPaddingMask(src, padding_idx).to(device)
#     tgt_self_mask = UTools_createDecoderSelfAttentionMask(tgt, padding_idx).to(device)
#     cross_mask = UTools_createCrossAttentionMask(tgt, src, padding_idx).to(device)
    
#     print(f"æºåºåˆ—æ©ç å½¢çŠ¶: {src_mask.shape}")
#     print(f"ç›®æ ‡åºåˆ—è‡ªæ³¨æ„åŠ›æ©ç å½¢çŠ¶: {tgt_self_mask.shape}")
#     print(f"äº¤å‰æ³¨æ„åŠ›æ©ç å½¢çŠ¶: {cross_mask.shape}")
    
#     # å‰å‘ä¼ æ’­
#     try:
#         transformer.eval()
#         output, encoder_output, enc_attn_weights, dec_self_attn_weights, dec_cross_attn_weights = transformer(
#             src, tgt, src_mask, tgt_self_mask, cross_mask
#         )
        
#         print("âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
#         print(f"è§£ç å™¨è¾“å‡ºlogitså½¢çŠ¶: {output.shape}")
#         print(f"ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶: {encoder_output.shape}")
#         print(f"ç¼–ç å™¨æ³¨æ„åŠ›æƒé‡å±‚æ•°: {len(enc_attn_weights)}")
#         print(f"è§£ç å™¨è‡ªæ³¨æ„åŠ›æƒé‡å±‚æ•°: {len(dec_self_attn_weights)}")
#         print(f"è§£ç å™¨äº¤å‰æ³¨æ„åŠ›æƒé‡å±‚æ•°: {len(dec_cross_attn_weights)}")
        
#         # éªŒè¯å½¢çŠ¶
#         assert output.shape == (batch_size, tgt_seq_len, tgt_vocab_size), "è¾“å‡ºlogitså½¢çŠ¶é”™è¯¯"
#         assert encoder_output.shape == (batch_size, src_seq_len, d_model), "ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶é”™è¯¯"
#         assert len(enc_attn_weights) == num_layers, "ç¼–ç å™¨æ³¨æ„åŠ›æƒé‡å±‚æ•°é”™è¯¯"
#         assert len(dec_self_attn_weights) == num_layers, "è§£ç å™¨è‡ªæ³¨æ„åŠ›æƒé‡å±‚æ•°é”™è¯¯"
#         assert len(dec_cross_attn_weights) == num_layers, "è§£ç å™¨äº¤å‰æ³¨æ„åŠ›æƒé‡å±‚æ•°é”™è¯¯"
        
#         # éªŒè¯å•ä¸ªæ³¨æ„åŠ›æƒé‡å½¢çŠ¶
#         for i, attn in enumerate(enc_attn_weights):
#             assert attn.shape == (batch_size, num_heads, src_seq_len, src_seq_len), f"ç¼–ç å™¨ç¬¬{i}å±‚æ³¨æ„åŠ›æƒé‡å½¢çŠ¶é”™è¯¯"
        
#         for i, attn in enumerate(dec_self_attn_weights):
#             assert attn.shape == (batch_size, num_heads, tgt_seq_len, tgt_seq_len), f"è§£ç å™¨è‡ªæ³¨æ„åŠ›ç¬¬{i}å±‚æƒé‡å½¢çŠ¶é”™è¯¯"
        
#         for i, attn in enumerate(dec_cross_attn_weights):
#             assert attn.shape == (batch_size, num_heads, tgt_seq_len, src_seq_len), f"è§£ç å™¨äº¤å‰æ³¨æ„åŠ›ç¬¬{i}å±‚æƒé‡å½¢çŠ¶é”™è¯¯"
        
#         print("âœ… æ‰€æœ‰å½¢çŠ¶éªŒè¯é€šè¿‡")
        
#         # æµ‹è¯•å•ç‹¬çš„ç¼–ç å™¨å’Œè§£ç å™¨
#         print("\n--- æµ‹è¯•å•ç‹¬ç»„ä»¶ ---")
#         encoder_output_single, enc_attn_weights_single = transformer.encode(src, src_mask)
#         print(f"å•ç‹¬ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶: {encoder_output_single.shape}")
        
#         decoder_output_single, dec_self_attn_single, dec_cross_attn_single = transformer.decode(
#             tgt, encoder_output_single, tgt_self_mask, cross_mask
#         )
#         print(f"å•ç‹¬è§£ç å™¨è¾“å‡ºå½¢çŠ¶: {decoder_output_single.shape}")
        
#         # éªŒè¯å•ç‹¬ç»„ä»¶è¾“å‡ºä¸å®Œæ•´æ¨¡å‹ä¸€è‡´
#         assert torch.allclose(encoder_output_single, encoder_output, atol=1e-6), "å•ç‹¬ç¼–ç å™¨è¾“å‡ºä¸å®Œæ•´æ¨¡å‹ä¸ä¸€è‡´"
#         print("âœ… å•ç‹¬ç»„ä»¶æµ‹è¯•é€šè¿‡")
        
#         return True
        
#     except Exception as e:
#         print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
#         import traceback
#         traceback.print_exc()
#         return False

# def run_all_tests():
#   """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
#   print("âœ¨ å¼€å§‹è¿è¡ŒTransformeræ¨¡å‹æµ‹è¯• âœ¨\n")
#   test1_success = test_transformer_complete()
#   print(f"å®Œæ•´æ¨¡å‹æµ‹è¯•: {'âœ… é€šè¿‡' if test1_success else 'âŒ å¤±è´¥'}")

def tokenize_and_encode(text, word2id, BOS=1, EOS=2, UNK=3, add_bos_eos=True):
  '''
    å°†å¥å­è½¬ä¸º ID åºåˆ—ï¼ˆè‡ªåŠ¨æ·»åŠ  bos/eosï¼‰
  '''
  ids = [word2id.get(w, UNK) for w in text.split()]
  if add_bos_eos:
    ids = [BOS]+ids+[EOS]
  return ids

def simple_transformer_example():
  examples = [
    ("ich spreche flieÃŸend englisch .", "i speak fluent english ."),
    ("wir sind im kino .", "we are in the cinema ."),
    ("das ist die toilette .", "this is the toilet ."),
    ("sie geht ins kino .", "she is going to the cinema ."),
    ("ich bin flieÃŸend .", "i am fluent ."),
    # ("wo ist das buch ?", "where is this book ?"),
    ("wir lieben dieses buch .", "we love this book ."),
    ("sie ist im kino .", "she is in the cinema ."),
    ("ich gehe ins kino .", "i am going to the cinema ."),
    ("das ist flieÃŸend englisch .", "this is fluent english ."),
    ("guten morgen , ich bin flieÃŸend .", "good morning , i am fluent ."),
    ("sie liebt dich .", "she loves you ."),
    ("das buch ist flieÃŸend .", "this book is fluent ."),
    ("ich liebe dieses buch .", "i love this book ."),
    ("sie liebt das buch .", "she loves the book ."),
    ("ich bin im buch .", "i am in the book ."),
    ("ist das buch flieÃŸend ?", "is this book fluent ?"),
    ("wo ist das kino ?", "where is the cinema ?"),
    # ("wo ist dieses kino ?", "where is this cinema ?"),
    ("wo ist das morgen ?", "where is the morning ?"),
    ("wo ist flieÃŸend englisch ?", "where is fluent english ?"),
    ("wo ist ich ?", "where is i ?"),
    ("wo ist wir ?", "where is we ?"),
    ("wo ist sie ?", "where is she ?"),
  ]
  test_examples = [
    ("wo ist das buch ?", "where is this book ?"),
    ("wo ist dieses kino ?", "where is this cinema ?"),
  ]
  PAD, BOS, EOS, UNK = 0, 1, 2, 3
  special_tokens = ["<pad>", "<bos>", "<eos>", "<unk>"]

  # æ”¶é›†è¯æ±‡
  src_words = set()
  tgt_words = set()
  for de, en in examples:
    src_words.update(de.split())
    tgt_words.update(en.split())
  src_vocab = special_tokens + sorted(src_words)    # å…¨éƒ¨çš„å¾·è¯­ï¼ˆè¾“å…¥æ•°æ®ï¼‰
  tgt_vocab = special_tokens + sorted(tgt_words)    # å…¨éƒ¨çš„è‹±è¯­ï¼ˆè¾“å‡ºæ•°æ®ï¼‰
  print(f"ğŸ‡©ğŸ‡ª æºè¯è¡¨å¤§å°: {len(src_vocab)} | ğŸ‡¬ğŸ‡§ ç›®æ ‡è¯è¡¨å¤§å°: {len(tgt_vocab)}")

  src_word2id = {w: i for i, w in enumerate(src_vocab)}
  tgt_word2id = {w: i for i, w in enumerate(tgt_vocab)}
  tgt_id2word = {i: w for w, i in tgt_word2id.items()}
  src_seqs = [tokenize_and_encode(de, src_word2id) for de, _ in examples]   # å°†æ‰€æœ‰å¾·è¯­å¥å­ç”¨token idsè¡¨ç¤º
  tgt_seqs = [tokenize_and_encode(en, tgt_word2id) for _, en in examples]   # å°†æ‰€æœ‰è‹±è¯­å¥å­ç”¨token idsè¡¨ç¤º

  src_batch = pad_sequence([torch.tensor(s) for s in src_seqs], batch_first=True, padding_value=PAD).to(device)
  tgt_batch = pad_sequence([torch.tensor(t) for t in tgt_seqs], batch_first=True, padding_value=PAD).to(device)
  # å°†æ‰€æœ‰token idså¡«å……åè¡¨ç¤º
  # pad_sequence(..., batch_first=True, padding_value=PAD): 
  #     batch_first - è¾“å‡ºå½¢çŠ¶ä¸º (batch_size, L_max)
  #     padding_value=PAD - æŒ‡å®šå¡«å……çš„æ•°å€¼ï¼ˆè¿™é‡Œç”¨ 0 è¡¨ç¤º <pad>ï¼‰
  print(f'src={src_batch.shape}, tgt={tgt_batch.shape}')
  
  # åˆ›å»ºæ¨¡å‹
  model = Transformer(
    src_vocab_size=len(src_vocab),
    tgt_vocab_size=len(tgt_vocab),
    d_model=256,
    num_layers=6,
    num_heads=8,
    d_ff=512,
    max_seq_length=20,
    dropout=0.1,
    padding_idx=PAD
  ).to(device)
  criterion = nn.CrossEntropyLoss(ignore_index=PAD)
  optimizer = optim.Adam(model.parameters(), lr=3e-4)

  # è®­ç»ƒè¿‡ç¨‹
  model.train()
  for step in range(200):
    optimizer.zero_grad()
    
    # æ„å»ºæ©ç 
    src_mask = UTools_createPaddingMask(src_batch, PAD).to(device)
    tgt_self_mask = UTools_createDecoderSelfAttentionMask(tgt_batch, PAD).to(device)
    cross_mask = UTools_createCrossAttentionMask(tgt_batch, src_batch, PAD).to(device)
    
    # å‰å‘ â†’ [B, T, V]
    logits, *_ = model(src_batch, tgt_batch, src_mask, tgt_self_mask, cross_mask)
    
    # å¯¹é½ï¼šé¢„æµ‹ tgt[i] â† tgt[:i]
    y_true = tgt_batch[:, 1:]      # <bos> w1 w2 ... <eos> â†’ w1 w2 ... <eos>
    y_pred = logits[:, :-1, :]    # é¢„æµ‹é•¿åº¦éœ€åŒ¹é…
    # print(y_true, y_true.shape)
    
    loss = criterion(y_pred.reshape(-1, len(tgt_vocab)), y_true.reshape(-1))
    loss.backward()
    optimizer.step()
    
    print(f"Step {step+1:2d} | Loss: {loss.item():.4f}")

  # æ¨ç†è¿‡ç¨‹
  model.eval()
  results = []
  with torch.no_grad():
    for i, (de_sent, en_ref) in enumerate(test_examples):
      # ç¼–ç æºå¥
      src_ids = torch.tensor(tokenize_and_encode(de_sent, src_word2id)).unsqueeze(0).to(device)  # [1, L]
      src_mask = UTools_createPaddingMask(src_ids, PAD).to(device)
      enc_out, _ = model.encode(src_ids, src_mask)

      # è‡ªå›å½’ç”Ÿæˆ
      tgt_input = torch.tensor([[BOS]]).to(device)  # åˆå§‹ <bos>
      generated = []

      for _ in range(15):  # æœ€å¤§ç”Ÿæˆé•¿åº¦
        tgt_self_mask = UTools_createDecoderSelfAttentionMask(tgt_input, PAD).to(device)
        cross_mask = UTools_createCrossAttentionMask(tgt_input, src_ids, PAD).to(device)
        logits, *_ = model.decode(tgt_input, enc_out, tgt_self_mask, cross_mask)
        # print(logits, logits.shape)
        next_token = logits[0, -1].argmax().item()
        if next_token == EOS:
            break
        generated.append(next_token)
        tgt_input = torch.cat([tgt_input, torch.tensor([[next_token]]).to(device)], dim=1)

      # è§£ç ä¸ºæ–‡æœ¬
      pred_words = [tgt_id2word.get(tid, '<unk>') for tid in generated]
      pred_sent = " ".join(pred_words)
      results.append((de_sent, en_ref, pred_sent))

  # ===== å¯¹æ¯”å±•ç¤º =====
  print("\n{:<25} | {:<30} | {:<30}".format("ğŸ‡©ğŸ‡ª å¾·è¯­è¾“å…¥", "ğŸ‡¬ğŸ‡§ çœŸå®è‹±è¯­", "æ¨¡å‹ç”Ÿæˆ"))
  print("-" * 90)
  for de, ref, pred in results:
    # æ¸…ç†æ ‡ç‚¹å‰çš„ç©ºæ ¼ï¼ˆå¦‚ " ." â†’ "."ï¼‰
    ref = ref.replace(" .", ".").replace(" ?", "?").replace(" !", "!")
    pred = pred.replace(" .", ".").replace(" ?", "?").replace(" !", "!")
    print(f"{de:<25} | {ref:<30} | {pred:<30}")  

if __name__ == "__main__":
#   run_all_tests()
  print("\n=================å¼€å§‹Transformerç®€å•ä½¿ç”¨ç¤ºä¾‹=====================\n")
  simple_transformer_example()
