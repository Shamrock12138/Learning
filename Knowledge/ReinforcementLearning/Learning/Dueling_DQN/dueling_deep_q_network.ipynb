{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2ac751",
   "metadata": {},
   "source": [
    "### Dueling DQN(DDQN)介绍\n",
    "\n",
    "  **\"在某些状态下，选择哪个动作并不重要，重要的是这个状态本身的价值\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28afd7d",
   "metadata": {},
   "source": [
    "#### Dueling DQN核心思想\n",
    "\n",
    "  **标准DQN**\n",
    "  $$Q(s,a; \\theta) = f_{\\theta}(s,a)$$\n",
    "\n",
    "  **Dueling DQN**：\n",
    "  $$Q(s,a; \\theta, \\alpha, \\beta) = V(s; \\theta, \\beta) + \\left(A(s,a; \\theta, \\alpha) - \\frac{1}{|A|}\\sum_{a'}A(s,a'; \\theta, \\alpha)\\right)$$\n",
    "\n",
    "  其中：\n",
    "  - $V(s; \\theta, \\beta)$：状态价值函数，评估状态s的内在价值\n",
    "  - $A(s,a; \\theta, \\alpha)$：动作优势函数，评估动作a相对于平均动作的优劣\n",
    "  - $\\frac{1}{|A|}\\sum_{a'}A(s,a'; \\theta, \\alpha)$：确保Q值分解的唯一性\n",
    "\n",
    "  优势函数A(s, a) = V(s)+Q(s, a)，通过NN同时训练得到A和V，只需修改V(s)便可达到修改Q(s, an)的效果。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
