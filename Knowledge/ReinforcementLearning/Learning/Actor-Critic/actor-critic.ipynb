{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee83cac",
   "metadata": {},
   "source": [
    "### Actor-Critic(AC)介绍\n",
    "\n",
    "AC算法结合了**策略梯度方法（Actor）**和**值函数估计方法（Critic）**的优点\n",
    "  - Actor 学习策略函数 π(a|s;θ)，负责生成动作\n",
    "  - Critic 学习值函数 V(s;w) 或 Q(s,a;w)，评估当前策略的好坏\n",
    "\n",
    "#### **策略梯度定理（Policy Gradient Theorem）**\n",
    "\n",
    "该定理指出，$J(\\theta)$ 关于 $\\theta$ 的梯度为：\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta J(\\theta) = \\mathbb{E}_{s \\sim d^\\pi,\\, a \\sim \\pi_\\theta} \\left[ \\nabla_\\theta \\log \\pi_\\theta(a|s) \\cdot A^\\pi(s, a) \\right]\n",
    "$$\n",
    "\n",
    "- $d^\\pi(s)$：状态 $s$ 在策略 $\\pi$ 下的访问分布；\n",
    "- $A^\\pi(s, a) = Q^\\pi(s, a) - V^\\pi(s)$：优势函数，表示“采取动作 $a$ 比平均好多少”。\n",
    "\n",
    "#### **TD Error**\n",
    "\n",
    "Critic 使用 **TD 误差** 作为学习信号，也作为 Actor 的优势函数近似：\n",
    "\n",
    "$$\n",
    "\\delta_t = r_t + \\gamma V(s_{t+1}; w) - V(s_t; w)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b429ebf1",
   "metadata": {},
   "source": [
    "#### **Actor更新**\n",
    "\n",
    "使用策略梯度定理，目标是最大化期望回报，梯度为：\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta J(\\theta) = \\mathbb{E} \\left[ \\delta_t \\, \\nabla_\\theta \\log \\pi(a_t | s_t; \\theta) \\right]\n",
    "$$\n",
    "\n",
    "因此，Actor 参数更新为：\n",
    "\n",
    "$$\n",
    "\\theta \\leftarrow \\theta + \\alpha_\\theta \\, \\delta_t \\, \\nabla_\\theta \\log \\pi(a_t | s_t; \\theta)\n",
    "$$\n",
    "\n",
    "其中 $\\alpha_\\theta$ 是 Actor 的学习率。\n",
    "\n",
    "> ✅ 注意：$\\delta_t$ 在此充当**优势函数** $A(s_t, a_t) = Q(s_t, a_t) - V(s_t)$ 的无偏估计（因 $Q(s_t, a_t) \\approx r_t + \\gamma V(s_{t+1})$）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b73f956",
   "metadata": {},
   "source": [
    "#### **Critic更新**\n",
    "\n",
    "最小化 TD 误差的平方损失：\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{critic}}(w) = \\frac{1}{2} \\delta_t^2\n",
    "$$\n",
    "\n",
    "梯度下降更新：\n",
    "\n",
    "$$\n",
    "w \\leftarrow w + \\alpha_w \\, \\delta_t \\, \\nabla_w V(s_t; w)\n",
    "$$\n",
    "\n",
    "其中 $\\alpha_w$ 是 Critic 的学习率。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
