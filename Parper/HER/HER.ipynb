{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb11cfa",
   "metadata": {},
   "source": [
    "### Hindsight Experience Replay (HER, 事后经验回放)\n",
    "\n",
    "  * 论文：\n",
    "\n",
    "    * 《Hindsight Experience Replay》  \n",
    "      （Neural Information Processing Systems 2017）\n",
    "\n",
    "  * 核心思想:  \n",
    "    在经验回放时，用不同于原定目标的其他目标（例如该轨迹中实际达成的某个状态）来重播整个轨迹，从而将失败经历转化为对新目标的有用训练数据。\n",
    "\n",
    "    例如：MORL中使用当前偏好w采样的trajectory：(s, a, r, n_s)，可以通过HER拓展为每个偏好w'的采样，即(w', s, a, r, n_s)。实现了一次真实采样，可以扩展为n次‘虚拟’采样，大大提升了样本效率。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
